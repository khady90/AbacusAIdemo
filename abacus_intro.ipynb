{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a42b801-e7df-4f6b-90af-95518235975c",
   "metadata": {},
   "source": [
    "# Install or upgreade an required package into notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19afb9a8-ee1d-417f-bc85-153f18a57003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install abacusai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7a0fd-63f0-4b92-ae9b-08347315718b",
   "metadata": {},
   "source": [
    "# Import Packages required\n",
    "## We will be using pandas and the Abacus.ai client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b197b2e-de22-44d4-afee-eafaf061bef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from abacusai import ApiClient, ApiException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308ae9ec-0979-46e9-a80e-60b3dfb6a293",
   "metadata": {},
   "source": [
    "# Build a local model\n",
    "To begin, we'll read a dataset from s3 into a pandas dataframe. We then manipulate the data, prepare it for training and train a model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770ec46-1110-4be5-825c-0077ffe4a8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concrete_df = pd.read_csv(\n",
    "    \"s3://abacusai-exampledatasets/predicting/concrete_measurements.csv\"\n",
    ")\n",
    "concrete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906b6f0-6501-401c-a346-a3772fae8e3a",
   "metadata": {},
   "source": [
    "### We perform a simple transform. Please be sure to provide a constant we utilize in our transform function\n",
    "Importing pandas directly in the function body is important for later. Be sure to test your transform function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfbc008-83ac-4d55-a36f-4d54ad62b556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_concrete(concrete_dataframe):\n",
    "    import pandas as pd\n",
    "\n",
    "    constant = None\n",
    "    assert constant, \"Please provide a constant to use in featurization\"\n",
    "    # Remove the flyash feature\n",
    "    feature_df = concrete_dataframe.drop([\"flyash\"], axis=1).copy()\n",
    "    # DataFrame with rows where flyash == 0\n",
    "    no_flyash = feature_df[concrete_dataframe[\"flyash\"] == 0.0].copy()\n",
    "    no_flyash.loc[:, \"slag\"] = no_flyash[\"slag\"] - no_flyash[\"water\"].mean()\n",
    "    # DataFrame with rows where flyash > 0\n",
    "    flyash = feature_df[concrete_dataframe[\"flyash\"] > 0.0].copy()\n",
    "    flyash.loc[:, \"slag\"] = flyash[\"slag\"] + constant\n",
    "    return pd.concat([no_flyash, flyash - flyash.assign(age=0).mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2a24d-65f5-4403-aaf6-d22c6303938e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_concrete_df = transform_concrete(concrete_df)\n",
    "transformed_concrete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2304e-e8c4-4be1-95ef-575e73354ed2",
   "metadata": {},
   "source": [
    "### We now prepare the data for training by splitting it between a train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f825a2-13fe-480c-91ac-63a1da3daaf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_train_test_split(data_to_split):\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    training_data, prediction_data = train_test_split(\n",
    "        data_to_split.copy(), test_size=0.1, train_size=0.9, random_state=42\n",
    "    )\n",
    "    training_data[\"TRAINTEST\"] = \"TRAIN\"\n",
    "    prediction_data[\"TRAINTEST\"] = \"TEST\"\n",
    "    return pd.concat([training_data, prediction_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce82ef4-782f-448c-a95e-45114f9669ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concrete_train_test = assign_train_test_split(transformed_concrete_df)\n",
    "concrete_training_data = concrete_train_test.loc[\n",
    "    concrete_train_test[\"TRAINTEST\"] == \"TRAIN\"\n",
    "].drop(columns={\"TRAINTEST\"}, axis=1)\n",
    "concrete_prediction_data = concrete_train_test.loc[\n",
    "    concrete_train_test[\"TRAINTEST\"] == \"TEST\"\n",
    "].drop(columns={\"TRAINTEST\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf81f2c-feb5-433f-aa6c-8820b9fa7ad1",
   "metadata": {},
   "source": [
    "## Define a local training and predict function\n",
    "We define a simple linear regression model that utilizes a quantile transformer for numeric columns. We also define a prediction function. Of course, we execute both of these to ensure they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ac24a-0ef7-44e6-b9d1-2b2cf1f5420a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(training_dataset):\n",
    "    import numpy as np\n",
    "\n",
    "    # set the seed for reproduceable results\n",
    "    np.random.seed(5)\n",
    "\n",
    "    target_column = \"csMPa\"\n",
    "    X = training_dataset.drop([target_column], axis=1).copy()\n",
    "    y = training_dataset[target_column]\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "    qt = QuantileTransformer(n_quantiles=20)\n",
    "    linear_regresion = LinearRegression()\n",
    "    linear_regresion.fit(qt.fit_transform(X), y)\n",
    "    print(f\"Linear model R^2 = {linear_regresion.score(qt.transform(X), y)}\")\n",
    "\n",
    "    return (X.columns, target_column, qt, linear_regresion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d75900-1dda-43f9-822c-ddd827596af6",
   "metadata": {},
   "source": [
    "### Examine the train function outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec2283-ace1-4444-bae2-fe5e5707d767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_model = train(concrete_training_data)\n",
    "input_columns, target, transform, model = local_model\n",
    "print(input_columns)\n",
    "print(target)\n",
    "print(transform)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6e973-f015-44ee-b02f-b1b1cc2c21d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_many(model, queries):\n",
    "    input_columns, target_column, qt, model = model\n",
    "    import pandas as pd\n",
    "\n",
    "    predictions = []\n",
    "    for query in queries:\n",
    "        X = pd.DataFrame({c: [query[c]] for c in input_columns})\n",
    "        y = model.predict(qt.transform(X))\n",
    "        predictions.append({target_column: y[0]})\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d4e73-ac20-41fa-8123-18629518a779",
   "metadata": {},
   "source": [
    "### Let's see what our model is predicting\n",
    "We aren't too worried about performance for our toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa73d75-ded7-4fc8-a66b-e471e4771117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_results = predict_many(\n",
    "    local_model, concrete_prediction_data.to_dict(orient=\"records\")\n",
    ")\n",
    "prediction_results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f06c86-4697-4262-aa09-3e222265f5e5",
   "metadata": {},
   "source": [
    "# Incorporate our Model into Abacus\n",
    "With a working local model, we can now leverage the Abacus.ai client and our training/predict code to bring our model into the Abacus Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97d515-7f6d-488e-aca7-a3a7fe14f69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instatiate a client instance\n",
    "client = ApiClient(server='https://workshop.abacus.ai')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791c88f-b2ae-4ead-921b-eebb5c327f5e",
   "metadata": {},
   "source": [
    "## Creating our first project\n",
    "The first project we create is a Feature Store project. This will act as a location to store feature groups (data transformations) we create.\n",
    "https://workshop.abacus.ai/help/useCases/feature_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d968b-f9dc-43f3-8ffa-2877c135dc72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_store_project_name = \"\"\n",
    "assert (\n",
    "    feature_store_project_name\n",
    "), \"Please provide a name for your Feature Store Project\"\n",
    "\n",
    "feature_store_project_exists = False\n",
    "use_case = \"FEATURE_STORE\"\n",
    "feature_store_project = None\n",
    "\n",
    "for existing_project in client.list_projects():\n",
    "    if feature_store_project_name == existing_project.name:\n",
    "        feature_store_project_exists = True\n",
    "        feature_store_project = existing_project\n",
    "\n",
    "if not feature_store_project_exists:\n",
    "    feature_store_project = client.create_project(feature_store_project_name, use_case)\n",
    "feature_store_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7d1a0-ba42-4b0a-8eb7-d90690586a13",
   "metadata": {},
   "source": [
    "### Manipulating Data in Abacus\n",
    "We can leverage Feature Groups in Abacus.ai in order to manipulate and transform our data. Each feature group must have a unique, so we define a unique prefix variable for easy uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e770f8-4520-4933-af52-25d7db3c7ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_prefix = \"\"\n",
    "assert unique_prefix, \"Please provide a unique_prefix to avoid name collision\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551080e-f1df-4e0e-b193-1d647ec00c4c",
   "metadata": {},
   "source": [
    "## We can make Feature Groups directly from Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6b239-a1ed-4cfd-8ee1-d862278716d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concrete_feature_group_name = unique_prefix + \"concrete_attributes\"\n",
    "try:\n",
    "    concrete_feature_group = client.create_feature_group_from_pandas_df(\n",
    "        concrete_feature_group_name, df=concrete_df\n",
    "    )\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "    concrete_feature_group = client.describe_feature_group_by_table_name(\n",
    "        concrete_feature_group_name\n",
    "    )\n",
    "try:\n",
    "    concrete_feature_group.add_to_project(feature_store_project.id)\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "concrete_feature_group.add_tag(\"base_data\")\n",
    "concrete_feature_group.wait_for_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080662de-7cf5-42ad-b81e-00f4951628f1",
   "metadata": {},
   "source": [
    "## We can define generalized python functions to generate Feature Groups\n",
    "First we create the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa2f2d4-c9b7-4081-a191-1c81ebf2800e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_transform_function_name = unique_prefix + \"concrete_python_transformation\"\n",
    "try:\n",
    "    python_transform_function = client.create_python_function(\n",
    "        name=python_transform_function_name\n",
    "    )\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "    python_transform_function = client.describe_python_function(\n",
    "        python_transform_function_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc7c18-d3e9-4263-ab58-8d184851d60b",
   "metadata": {},
   "source": [
    "### We then update the functions code defintion. Just like a normal python function, we have variable mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a3a84-88bf-4424-9c8c-f0b953f1d75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_transform_function = client.update_python_function_code(\n",
    "    python_transform_function.name, function=transform_concrete\n",
    ")\n",
    "python_transform_function.function_variable_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a92aaa-8854-4cd9-bb75-32de7435d49c",
   "metadata": {},
   "source": [
    "### Next, we map inputs to our bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab64d2-07a0-40cb-a167-2b46f518732a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_input_feature_groups = [concrete_feature_group.table_name]\n",
    "transform_function_bindings = [\n",
    "    dict({\"value\": transform_input_feature_groups[index]}, **function_argument)\n",
    "    for index, function_argument in enumerate(\n",
    "        python_transform_function.function_variable_mappings\n",
    "    )\n",
    "]\n",
    "transform_function_bindings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af8426-4393-4c08-9e67-ffcdaa2695f6",
   "metadata": {},
   "source": [
    "### Finally, we can create a feature group from this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698ec88-7dd8-4008-8afa-4d47086b7c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_fg_name = unique_prefix + \"concrete_transform_fg\"\n",
    "try:\n",
    "    transform_fg = client.create_feature_group_from_function(\n",
    "        table_name=transform_fg_name,\n",
    "        python_function_name=python_transform_function.name,\n",
    "        python_function_bindings=transform_function_bindings,\n",
    "    )\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "    transform_fg = client.describe_feature_group_by_table_name(transform_fg_name)\n",
    "try:\n",
    "    transform_fg.add_to_project(feature_store_project.id)\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "transform_fg.add_tag(\"transform\")\n",
    "transform_fg.add_tag(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c6f76-b646-4912-84b7-82734d2aa760",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_fg.id, feature_store_project.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3330e-412c-4a0a-baf7-70bc7d88f93c",
   "metadata": {},
   "source": [
    "## We repeat the process, and can pass a python feature group as input to another python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2323368-ccde-4eab-b90e-00a8d008f85f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_split_function_name = unique_prefix + \"train_test_split\"\n",
    "try:\n",
    "    data_split_function = client.create_python_function(name=data_split_function_name)\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "    data_split_function = client.describe_python_function(data_split_function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8728eef-f921-4f6f-b993-831777fc06c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_split_function = client.update_python_function_code(\n",
    "    name=data_split_function_name, function=assign_train_test_split\n",
    ")\n",
    "data_split_function.function_variable_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a261af-477c-43b8-bb09-3f38c66a1a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_input_feature_groups = [transform_fg.table_name]\n",
    "data_split_bindings = [\n",
    "    dict({\"value\": split_input_feature_groups[index]}, **function_argument)\n",
    "    for index, function_argument in enumerate(\n",
    "        data_split_function.function_variable_mappings\n",
    "    )\n",
    "]\n",
    "data_split_bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01037ee9-083a-4104-9ea3-de04e223866e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_split_fg_name = unique_prefix + \"concrete_data_split_fg\"\n",
    "try:\n",
    "    data_split_fg = client.create_feature_group_from_function(\n",
    "        data_split_fg_name,\n",
    "        python_function_name=data_split_function.name,\n",
    "        python_function_bindings=data_split_bindings,\n",
    "    )\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "    data_split_fg = client.describe_feature_group_by_table_name(data_split_fg_name)\n",
    "try:\n",
    "    data_split_fg.add_to_project(feature_store_project.id)\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "data_split_fg.add_tag(\"data_split\")\n",
    "data_split_fg.add_tag(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d626729-5e34-460d-a918-001c9e33e475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_split_fg.materialize()\n",
    "data_split_fg.refresh().features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e99a57-37f7-4b8a-b419-bc70ff2eab73",
   "metadata": {},
   "source": [
    "# Not only Python Functions\n",
    "With Feature Groups, we can also execute SQL queries. Here we split our data between train and test using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635de2b-d394-43b8-87fb-79be00a78d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_feature_but_traintest = [\n",
    "    feature.name\n",
    "    for feature in data_split_fg.refresh().features\n",
    "    if feature.name != \"TRAINTEST\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e4c3e-b91c-48c9-ad28-ac04fb7d418f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concrete_training_data_fg_name = unique_prefix + \"concrete_training_data_fg\"\n",
    "train_sql = f\"SELECT {', '.join(all_feature_but_traintest)} FROM {data_split_fg.table_name} WHERE TRAINTEST = 'TRAIN'\"\n",
    "try:\n",
    "    concrete_training_data_fg = client.create_feature_group(\n",
    "        concrete_training_data_fg_name, sql=train_sql\n",
    "    )\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "    concrete_training_data_fg = client.describe_feature_group_by_table_name(\n",
    "        concrete_training_data_fg_name\n",
    "    )\n",
    "try:\n",
    "    concrete_training_data_fg.add_to_project(feature_store_project.id)\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "concrete_training_data_fg.add_tag(\"training\")\n",
    "concrete_training_data_fg.add_tag(\"sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d3b93-6075-4bf3-82d4-56ffe8cc0416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concrete_predicting_data_fg_name = unique_prefix + \"concrete_predicting_data_fg\"\n",
    "train_sql = f\"SELECT {', '.join(all_feature_but_traintest)} FROM {data_split_fg.table_name} WHERE TRAINTEST = 'TEST'\"\n",
    "try:\n",
    "    concrete_predicting_data_fg = client.create_feature_group(\n",
    "        concrete_predicting_data_fg_name, sql=train_sql\n",
    "    )\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "    concrete_predicting_data_fg = client.describe_feature_group_by_table_name(\n",
    "        concrete_predicting_data_fg_name\n",
    "    )\n",
    "try:\n",
    "    concrete_predicting_data_fg.add_to_project(feature_store_project.id)\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "concrete_predicting_data_fg.add_tag(\"predicting\")\n",
    "concrete_predicting_data_fg.add_tag(\"sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016286e3-fd44-49bf-a9a9-7665d558cb3c",
   "metadata": {},
   "source": [
    "# Abacus BYOA - Run your model alongside Abacus's world class algorithms\n",
    "With a handle on training a custom model in an Abacus notebook, we can now register a algorithm to run concurrently with Abacus' own algorithms. This allows us to make quick comparisons across models and helps control train and test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289946d-88cd-4795-b3c9-743eebb3da77",
   "metadata": {},
   "source": [
    "First we create a common Predictive Modeling project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed485f-9143-472d-b913-e3b76cc57c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "byoa_project_name = \"\"\n",
    "assert byoa_project_name, \"Please provide a name for your BYOA Project\"\n",
    "\n",
    "byoa_project_exists = False\n",
    "use_case = \"PREDICTING\"\n",
    "byoa_project = None\n",
    "\n",
    "for existing_project in client.list_projects():\n",
    "    if byoa_project_name == existing_project.name:\n",
    "        byoa_project_exists = True\n",
    "        byoa_project = existing_project\n",
    "\n",
    "if not byoa_project_exists:\n",
    "    byoa_project = client.create_project(byoa_project_name, use_case)\n",
    "byoa_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc470e-1dd3-492e-97bd-47f3fee76283",
   "metadata": {},
   "source": [
    "### Add the data split feature group to the project\n",
    "We also describe the requirements for the Predictive Modeling use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04253a0b-9271-493f-9718-1423e888a457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data_split_fg.add_to_project(byoa_project, feature_group_type=\"CUSTOM_TABLE\")\n",
    "except ApiException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f17cc-8326-4339-8c6e-5530b0c8722e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.describe_use_case_requirements(byoa_project.use_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88639ef4-0325-4f77-9702-885d48420224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T04:16:28.735524Z",
     "iopub.status.busy": "2022-11-15T04:16:28.735215Z",
     "iopub.status.idle": "2022-11-15T04:16:28.738083Z",
     "shell.execute_reply": "2022-11-15T04:16:28.737510Z",
     "shell.execute_reply.started": "2022-11-15T04:16:28.735506Z"
    }
   },
   "source": [
    "### With feature mapping requirements known, we set a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459eb241-ad0a-4869-9b83-8eb5cb7fd5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "byoa_project.set_feature_mapping(\n",
    "    data_split_fg.id, feature_name=\"csMPa\", feature_mapping=\"TARGET\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a12eaf-30a2-49db-8bf1-344328fed739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T04:19:13.826946Z",
     "iopub.status.busy": "2022-11-15T04:19:13.826406Z",
     "iopub.status.idle": "2022-11-15T04:19:13.829159Z",
     "shell.execute_reply": "2022-11-15T04:19:13.828725Z",
     "shell.execute_reply.started": "2022-11-15T04:19:13.826928Z"
    }
   },
   "source": [
    "### Validate the project and feature groups to ensure we're ready to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d20c4-6af3-4e40-9f6b-55d1a51e980d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "byoa_project.validate(feature_group_ids=[data_split_fg.id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fd9cf-ff8d-49ac-a147-72ec5c8fa361",
   "metadata": {},
   "source": [
    "### The client is self documenting, we can view the possible training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25aef1-274e-4d6d-a5af-8a73a920b637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.get_training_config_options(byoa_project.id, [data_split_fg.id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64372efb-199a-4442-94a9-f38b2827d9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T04:25:49.090601Z",
     "iopub.status.busy": "2022-11-15T04:25:49.089999Z",
     "iopub.status.idle": "2022-11-15T04:25:49.092724Z",
     "shell.execute_reply": "2022-11-15T04:25:49.092312Z",
     "shell.execute_reply.started": "2022-11-15T04:25:49.090581Z"
    }
   },
   "source": [
    "## Simulate running on Abacus locally\n",
    "We leverage specifically designed APIs to replicate how Abacus will pass input parameters to our training function to test locally. We can pass both Abacus and User configurations to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd721ba-46dd-442f-866a-aeaa069cc1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_table_names = [data_split_fg.table_name]\n",
    "abacus_ai_config = {\"TEST_ROW_INDICATOR\": \"TRAINTEST\"}\n",
    "user_config = {\"n_quantiles\": 20}\n",
    "import copy\n",
    "\n",
    "training_config = copy.deepcopy(abacus_ai_config)\n",
    "training_config.update({\"USER\": user_config})\n",
    "print(training_config)\n",
    "# Change the value of the parameter names if preferred, and don't forget to change in train_func as well.\n",
    "training_data_parameter_name_override = {\"CUSTOM_TABLE\": \"training_data\"}\n",
    "training_config_parameter_name_override = \"training_config\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9ae8e-f8c1-4ac2-8927-c454b3c04bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T04:27:24.984103Z",
     "iopub.status.busy": "2022-11-15T04:27:24.983410Z",
     "iopub.status.idle": "2022-11-15T04:27:24.986214Z",
     "shell.execute_reply": "2022-11-15T04:27:24.985777Z",
     "shell.execute_reply.started": "2022-11-15T04:27:24.984084Z"
    }
   },
   "source": [
    "### We manipulate the train function to fit the Abacus framework\n",
    "And train locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e876d2-75c3-4c3e-8096-81227f5690ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def byoa_train(training_data, schema_mappings, training_config):\n",
    "    import numpy as np\n",
    "\n",
    "    train_test_column = training_config.get(\"TEST_ROW_INDICATOR\", None)\n",
    "    user_defined_config = training_config.get(\"USER\")\n",
    "    n_quantiles = user_defined_config.get(\"n_quantiles\")\n",
    "\n",
    "    # set the seed for reproduceable results\n",
    "    np.random.seed(5)\n",
    "\n",
    "    target_columns = schema_mappings[\"training_data\"].get(\"TARGET\", [])\n",
    "    assert target_columns, \"No target column provided\"\n",
    "    ignore_columns = schema_mappings[\"training_data\"].get(\"IGNORE\", [])\n",
    "    drop_columns = target_columns + ignore_columns\n",
    "    drop_columns.append(train_test_column)\n",
    "    X = training_data.drop(drop_columns, axis=1).copy()\n",
    "    y = training_data[target_columns]\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "    qt = QuantileTransformer(n_quantiles=n_quantiles)\n",
    "    linear_regresion = LinearRegression()\n",
    "    linear_regresion.fit(qt.fit_transform(X), y)\n",
    "    print(f\"Linear model R^2 = {linear_regresion.score(qt.transform(X), y)}\")\n",
    "\n",
    "    return (X.columns, target_columns[0], qt, linear_regresion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d895c6-7242-461f-826a-768d0fe05e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This currently returns the full data for local testing, but on remote training, only the training rows are sent to the train_functin.\n",
    "train_input = client.get_train_function_input(\n",
    "    project_id=byoa_project.project_id,\n",
    "    training_table_names=training_table_names,\n",
    "    training_data_parameter_name_override=training_data_parameter_name_override,\n",
    "    training_config_parameter_name_override=training_config_parameter_name_override,\n",
    "    training_config=training_config,\n",
    ")\n",
    "# You can also override with any dataframe for local testing.\n",
    "model_input_table = data_split_fg.latest_feature_group_version.load_as_pandas()\n",
    "train_input[\"training_data\"] = model_input_table.loc[\n",
    "    model_input_table[\"TRAINTEST\"] == \"TRAIN\"\n",
    "]\n",
    "local_model = byoa_train(**train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e4c1d-27d4-4268-9213-99a613d27625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T04:29:25.052917Z",
     "iopub.status.busy": "2022-11-15T04:29:25.052451Z",
     "iopub.status.idle": "2022-11-15T04:29:25.055184Z",
     "shell.execute_reply": "2022-11-15T04:29:25.054744Z",
     "shell.execute_reply.started": "2022-11-15T04:29:25.052898Z"
    }
   },
   "source": [
    "### Similarly, we define a predict many function and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffdcae7-331c-4dea-8b76-733344790e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def byoa_predict_many(model, queries):\n",
    "    columns, target_column, qt, linear_model = model\n",
    "    import pandas as pd\n",
    "\n",
    "    result = []\n",
    "    for query in queries:\n",
    "        X = pd.DataFrame({c: [query[c]] for c in columns})\n",
    "        y = linear_model.predict(qt.transform(X))[0]\n",
    "        result.append({target_column: y[0]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88587c-e775-41b4-b046-d922b3b778be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_results = byoa_predict_many(\n",
    "    local_model, concrete_prediction_data.to_dict(orient=\"records\")\n",
    ")\n",
    "prediction_results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e074580-45d3-4c0b-ac31-19c9be9c61c1",
   "metadata": {},
   "source": [
    "# Registering the Algorithm\n",
    "We can register an algorithm at the project or organization level, but the name must always be all caps and begin with 'USER.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca7cde-b8ff-4676-b7f0-3d8ac9b510ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algorithm_scope = \"project\"\n",
    "algorithm_name = \"USER.\"\n",
    "assert algorithm_name.split(\".\")[1], \"Please provide an ALLCAPS name for your algorithm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c5f95-0e0a-4477-9298-7a4712477714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    byoa_algorithm = client.create_algorithm_from_function(\n",
    "        name=algorithm_name,\n",
    "        problem_type=\"REGRESSION\",\n",
    "        training_data_parameter_names_mapping=training_data_parameter_name_override,\n",
    "        training_config_parameter_name=training_config_parameter_name_override,\n",
    "        train_function=byoa_train,\n",
    "        predict_many_function=byoa_predict_many,\n",
    "    )\n",
    "except ApiException as e:\n",
    "    print(e)\n",
    "    byoa_algorithm = client.describe_algorithm(algorithm_name)\n",
    "byoa_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b028c91-7913-4a5f-841d-cf9ecf6b3f68",
   "metadata": {},
   "source": [
    "### With a registered Algorithm, we train our model, passing Abacus and User configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e782fe-473c-4982-94a5-40375708835c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "feature_group_ids = [\n",
    "    client.describe_feature_group_by_table_name(table_name).feature_group_id\n",
    "    for table_name in training_table_names\n",
    "]\n",
    "model_w_byoa = client.train_model(\n",
    "    project_id=byoa_project.id,\n",
    "    name=\"BYOA Regresion Model\",\n",
    "    training_config=abacus_ai_config,\n",
    "    feature_group_ids=feature_group_ids,\n",
    "    custom_algorithms=[algorithm_name],\n",
    "    custom_algorithm_configs={algorithm_name: json.dumps(user_config)},\n",
    "    # change to LARGE for extensive computation\n",
    "    cpu_size=\"MEDIUM\",\n",
    "    # max memory is 60GB\n",
    "    memory=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c416ae-1dd5-4177-810c-076fde9dff62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Wait for our specific Algorithm to complete training\n",
    "while algorithm_name not in [\n",
    "    algo[\"name\"]\n",
    "    for algo in model_w_byoa.describe().latest_model_version.deployable_algorithms\n",
    "]:\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(model_w_byoa.describe().latest_model_version.deployable_algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c2b6c-e1ef-4f56-8204-88d710b7f011",
   "metadata": {},
   "source": [
    "### We select our algorithm as the default in order to validate predictions\n",
    "Default algorithms are utilized in our deployment unless overridden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c785dda-2a58-4774-b365-21950ed20eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_w_byoa.set_default_algorithm(algorithm_name)\n",
    "byoa_deployment_token = client.create_deployment_token(\n",
    "    byoa_project.id, \"BYOA_Deployment_Token\"\n",
    ")\n",
    "byoa_deployment = client.create_deployment(\n",
    "    name=\"BYOA Deployment\", model_id=model_w_byoa.id\n",
    ")\n",
    "byoa_deployment.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceecd91-a9c0-48e2-8d2a-9f04edc945e3",
   "metadata": {},
   "source": [
    "### With our deployment we once again verify parity across the local predictions, the Abacus prediction API and Abacus Batch Prediction\n",
    "This verifies are models are all behaving the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47016c-5463-426c-8da5-1c6df5e52039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_results = byoa_predict_many(\n",
    "    local_model, concrete_prediction_data.to_dict(orient=\"records\")\n",
    ")\n",
    "prediction_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7816cca-9c0f-4bef-aa0b-60bd0ac7b6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for record in concrete_prediction_data.to_dict(orient=\"records\")[:5]:\n",
    "    print(\n",
    "        client.predict(\n",
    "            deployment_token=byoa_deployment_token,\n",
    "            deployment_id=byoa_deployment.id,\n",
    "            query_data=json.dumps(record),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22572eb-5e70-48b6-a127-e33df9c23111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "byoa_batch_prediction = byoa_deployment.create_batch_prediction(\n",
    "    table_name=\"byoa_evaluation_output\",\n",
    "    name=\"BYOA Evaluation Prediction\",\n",
    "    global_prediction_args={\"forEval\": True},\n",
    "    output_includes_metadata=True\n",
    ")\n",
    "byoa_batch_prediction_run = byoa_batch_prediction.start()\n",
    "byoa_batch_prediction_run.wait_for_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074c23c-421e-49b4-8a27-ce823bc2755a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "byoa_eval_output_fg = client.describe_feature_group_by_table_name(byoa_batch_prediction.feature_group_table_name)\n",
    "byoa_eval_output_fg.wait_for_materialization().latest_feature_group_version.load_as_pandas()['prediction_csMPa'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afeca79-6dce-4585-8a51-d025b8dd4361",
   "metadata": {},
   "source": [
    "# Congratulations\n",
    "You now can take a locally train a model, import it to Abacus as an independent, and import it to Abacus to run alongside our state of the art algorithms, competing against our Advanced AI systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b5257-549c-4667-a672-6f40ce48331d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[{'csMPa': 37.697797557944256},\n",
    " {'csMPa': 47.571887792434},\n",
    " {'csMPa': 64.70979460520971},\n",
    " {'csMPa': 43.66334359567851},\n",
    " {'csMPa': 13.843112761580656}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
